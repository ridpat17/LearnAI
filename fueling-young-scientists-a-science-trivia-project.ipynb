{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":97258,"sourceType":"competition"},{"sourceId":11452947,"sourceType":"datasetVersion","datasetId":7176015},{"sourceId":11452952,"sourceType":"datasetVersion","datasetId":7176019}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"As a busy parent, I'm always looking for ways to nurture my 8-year-old's budding curiosity, especially when it comes to science. Their enthusiastic participation in the North South Junior Science Bee sparked an idea: what if we could create a dynamic and engaging way for them to explore even more scientific concepts, tailored to their interests and learning pace?\n\nThat's where the magic of AI comes in! Inspired by the fascinating world of Generative AI and leveraging concepts I picked up from Kaggle's insightful 5-Day Gen AI course, I embarked on a project to build a science quiz platform using a powerful technique called Retrieval-Augmented Generation (RAG).\n\n# The Challenge: Beyond the Bee\n\nThe North South Junior Science Bee is fantastic, but learning shouldn't stop there. Finding relevant and engaging science quiz questions across diverse topics for an 8-year-old can be a real time sink. Existing resources can be too generic, too simplistic, or might not align with the specific areas my child is currently exploring. Plus, just getting the answer right isn't always the best way to learn. What truly helps is understanding why the answer is correct and having the opportunity to delve deeper.\n\n# Gen AI to the the Rescue: Creating a Dynamic Learning Tool\n\nThis project harnesses the power of several key Gen AI technologies to create a personalized and interactive science learning experience:\n\nDocument Understanding: Imagine being able to feed the AI various science materials – maybe interesting articles, textbook snippets, or even notes from the Science Bee itself! The AI can understand the content, identify the core ideas, and pull out the important stuff. In our case, we can even leverage the topics provided by organizations like northsouth.org as our knowledge base.\nEmbedding: This is where the AI truly starts to \"understand\" science. By converting the text from our documents into numerical representations called embeddings, the AI can grasp the relationships between different scientific concepts. Think of it like creating a map of knowledge where related ideas are close together. This allows the AI to find connections and identify questions relevant to specific topics.\nRetrieval-Augmented Generation (RAG): This is the heart of our quiz generator. When my child wants to test their knowledge on a specific topic (like \"the solar system\" or \"animal habitats\"), the AI uses the embeddings to find the most relevant information from the documents we've provided. This retrieved information then becomes the foundation for creating new and targeted quiz questions.\nPrompting: Just like guiding a helpful assistant, carefully crafted prompts tell the AI what kind of questions to create (multiple choice, perhaps?), how difficult they should be for an 8-year-old, and – crucially – to generate brief, easy-to-understand explanations for the correct answers. This is key for fostering genuine learning and encouraging further exploration.\n# Putting it All Together: An Interactive Science Adventure\n\nEssentially, Gen AI transforms static learning materials into an interactive adventure. Instead of relying on pre-made quizzes, we can dynamically generate questions tailored to my child's specific interests and learning needs. The immediate feedback and concise explanations provide a much richer learning experience, sparking curiosity and encouraging them to ask more questions.","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T16:47:17.797634Z","iopub.execute_input":"2025-04-20T16:47:17.797882Z","iopub.status.idle":"2025-04-20T16:47:20.002592Z","shell.execute_reply.started":"2025-04-20T16:47:17.797861Z","shell.execute_reply":"2025-04-20T16:47:20.001425Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/science-trivia-topics/2025_SLPGuide_08R_SC_JSC.pdf\n/kaggle/input/science-topics/2025_SLPGuide_08R_SC_JSC.pdf\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Setup\nFirst, install required libraries for this project","metadata":{}},{"cell_type":"code","source":"# Remove conflicting packages from the Kaggle base environment.\n!pip uninstall -qqy google-generativeai\n!pip install -qU google-genai langchain chromadb pypdf python-dotenv langchain-google-genai>=0.0.3 google-generativeai>=0.3.0 gtts langgraph langchain-community","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T16:47:24.925202Z","iopub.execute_input":"2025-04-20T16:47:24.925515Z","iopub.status.idle":"2025-04-20T16:48:23.978101Z","shell.execute_reply.started":"2025-04-20T16:47:24.925488Z","shell.execute_reply":"2025-04-20T16:48:23.976822Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from google import genai\nfrom google.genai import types\n\nfrom IPython.display import Markdown\n\ngenai.__version__","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T16:48:52.088208Z","iopub.execute_input":"2025-04-20T16:48:52.088642Z","iopub.status.idle":"2025-04-20T16:48:53.864234Z","shell.execute_reply.started":"2025-04-20T16:48:52.088612Z","shell.execute_reply":"2025-04-20T16:48:53.863367Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'1.11.0'"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"# Set up your API key\nTo run the following cell, your API key must be stored it in a Kaggle secret named GOOGLE_API_KEY.\n\nIf you don't already have an API key, you can grab one from AI Studio. You can find detailed instructions in the docs.\n\nTo make the key available through Kaggle secrets, choose Secrets from the Add-ons menu and follow the instructions to add your key or enable it for this notebook.","metadata":{}},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\nos.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T16:48:57.673612Z","iopub.execute_input":"2025-04-20T16:48:57.674112Z","iopub.status.idle":"2025-04-20T16:48:57.784306Z","shell.execute_reply.started":"2025-04-20T16:48:57.674086Z","shell.execute_reply":"2025-04-20T16:48:57.783389Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"If you received an error response along the lines of No user secrets exist for kernel id ..., then you need to add your API key via Add-ons, Secrets and enable it.\n\n![Screenshot of the checkbox to enable GOOGLE_API_KEY secret](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_3.png)","metadata":{}},{"cell_type":"markdown","source":"## Define Data Types\n\nDefine data types for the question and quiz state.","metadata":{}},{"cell_type":"code","source":"from typing import Dict, List, Any, TypedDict, Optional\n\nclass QuestionData(TypedDict):\n    question: str\n    options: List[str]\n    correct_answer: str\n    explanation: str\n    topic: str\n\nclass QuizState(TypedDict):\n    score: int\n    total_questions: int\n    current_question: Optional[QuestionData]\n    missed_questions: List[QuestionData]\n    status: str","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T16:49:01.689022Z","iopub.execute_input":"2025-04-20T16:49:01.689856Z","iopub.status.idle":"2025-04-20T16:49:01.695045Z","shell.execute_reply.started":"2025-04-20T16:49:01.689826Z","shell.execute_reply":"2025-04-20T16:49:01.694069Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## Initialize Models and Database","metadata":{}},{"cell_type":"code","source":"from langchain_google_genai import GoogleGenerativeAI\nfrom langchain_google_genai import GoogleGenerativeAIEmbeddings\nfrom langchain.chains import LLMChain\nfrom langchain.prompts import PromptTemplate\nimport google.generativeai as genai\n\ngenai.configure(api_key=os.getenv('GOOGLE_API_KEY'))\n\n# Initialize Gemini model and embeddings\nllm = GoogleGenerativeAI(model=\"gemini-2.0-flash\", \n                        google_api_key=os.getenv(\"GOOGLE_API_KEY\"))\n\n# Use Google Generative AI Embeddings\nembeddings = GoogleGenerativeAIEmbeddings(\n    model=\"models/text-embedding-004\",\n    google_api_key=os.getenv(\"GOOGLE_API_KEY\")\n)\n\n# Create prompt template for generating questions\nquestion_prompt = PromptTemplate(\n    input_variables=[\"context\", \"topic\"],\n    template=\"\"\"\n    Based on the following context about {topic}, create a science quiz question for 8 year old.\n    \n    Context:\n    {context}\n    \n    Format your response as a JSON object with the following structure:\n    {{\n        \"question\": \"A clear, concise question about the topic\",\n        \"options\": [\"Option 1\", \"Option 2\", \"Option 3\", \"Option 4\"],\n        \"correct_answer\": \"The correct option (must be exactly one of the options)\",\n        \"explanation\": \"A brief explanation of why the answer is correct\",\n        \"topic\": \"{topic}\"\n    }}\n    \n    Make sure the question tests understanding of the concept, not just memorization.\n    The options should be distinct and plausible.\n    \"\"\"\n)\n\nquestion_chain = LLMChain(llm=llm, prompt=question_prompt)\n\n# Create prompt template for topic extraction\ntopic_extraction_prompt = PromptTemplate.from_template(\n    \"Extract the main science topics from this text as a comma-separated list: {text}\"\n)\n\n# Create chain for topic extraction\ntopic_extraction_chain = LLMChain(llm=llm, prompt=topic_extraction_prompt)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T16:49:06.373782Z","iopub.execute_input":"2025-04-20T16:49:06.374136Z","iopub.status.idle":"2025-04-20T16:49:09.406105Z","shell.execute_reply.started":"2025-04-20T16:49:06.374111Z","shell.execute_reply":"2025-04-20T16:49:09.405000Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/2482954569.py:42: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n  question_chain = LLMChain(llm=llm, prompt=question_prompt)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## Initialize Vector Database\n\nDocument Processing: The application loads a science guide PDF and splits it into chunks.\n\nVector Database: It creates a vector database using Google Gemini embeddings.","metadata":{}},{"cell_type":"code","source":"from langchain.document_loaders import PyPDFLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.vectorstores import Chroma\n\n# Constants\nDB_DIR = \"googlecardb\"\nPDF_PATH = \"/kaggle/input/science-trivia-topics/2025_SLPGuide_08R_SC_JSC.pdf\"\n\ndef initialize_database() -> Chroma:\n    \"\"\"Initialize the vector database with science topics from the PDF\"\"\"\n    try:\n        # Load PDF document\n        loader = PyPDFLoader(PDF_PATH)\n        documents = loader.load()\n        \n        # Split text into chunks\n        text_splitter = RecursiveCharacterTextSplitter(\n            chunk_size=1000,\n            chunk_overlap=200\n        )\n        splits = text_splitter.split_documents(documents)\n        \n        # Create and return ChromaDB instance\n        return Chroma.from_documents(\n            documents=splits,\n            embedding=embeddings,\n            persist_directory=DB_DIR\n        )\n    except Exception as e:\n        print(f\"Error initializing database: {e}\")\n        # If PDF loading fails, create an empty database\n        return Chroma(\n            embedding_function=embeddings,\n            persist_directory=DB_DIR\n        )\n\n# Initialize the database\ndb = initialize_database()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T16:49:16.555529Z","iopub.execute_input":"2025-04-20T16:49:16.556074Z","iopub.status.idle":"2025-04-20T16:49:18.676864Z","shell.execute_reply.started":"2025-04-20T16:49:16.556046Z","shell.execute_reply":"2025-04-20T16:49:18.676045Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## Extract Topics from the Database\n\nTopic Extraction: It extracts main science topics from the document.","metadata":{}},{"cell_type":"code","source":"def extract_topics() -> List[str]:\n    \"\"\"Extract main topics from the database\"\"\"\n    try:\n        # Query the database for main topics\n        results = db.similarity_search(\"What are the main science topics covered in this document?\", k=5)\n        \n        # Extract topics from the results\n        all_topics = []\n        for doc in results:\n            # Use Gemini to extract topics from the document\n            response = topic_extraction_chain.invoke({\"text\": doc.page_content})\n            extracted_topics = [topic.strip() for topic in response[\"text\"].split(\",\")]\n            all_topics.extend(extracted_topics)\n        \n        # Remove duplicates and return\n        seen = set()\n        unique_topics = [topic for topic in all_topics if not (topic in seen or seen.add(topic))]\n        topics = unique_topics\n        return list(set(topics))\n        \n    except Exception as e:\n        print(f\"Error extracting topics: {e}\")\n        # Return default topics if extraction fails\n        return [\n            \"Physics\", \"Chemistry\", \"Biology\", \"Earth Science\", \"Astronomy\",\n            \"Ecology\", \"Genetics\", \"Human Body\", \"Energy\", \"Matter\"\n        ]\n\n# Extract topics\ntopics = extract_topics()\n\n# Display available topics\nprint(\"Available science topics:\")\nfor i, topic in enumerate(topics, 1):\n    print(f\"{i}. {topic}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T16:49:29.852362Z","iopub.execute_input":"2025-04-20T16:49:29.853262Z","iopub.status.idle":"2025-04-20T16:49:32.810728Z","shell.execute_reply.started":"2025-04-20T16:49:29.853224Z","shell.execute_reply":"2025-04-20T16:49:32.809870Z"}},"outputs":[{"name":"stdout","text":"Available science topics:\n1. Rocks\n2. wind\n3. Speed\n4. Kinetic Energy\n5. precipitation\n6. water vapor\n7. Force\n8. Physical Sciences\n9. Landforms\n10. Seasons\n11. Gravity\n12. water cycle\n13. condensation\n14. soil\n15. Climate\n16. weather instruments\n17. clouds\n18. evaporation\n19. storms\n20. Simple Machines\n21. Plant Adaptations\n22. Animal Adaptations\n23. Habitats\n24. Light Energy\n25. drought\n26. Life Sciences\n27. Food Webs\n28. Earth Sciences\n29. Human Adaptations\n30. Food Chains\n31. Scientific Inquiry\n32. Sound Energy\n33. Soil types\n34. Erosion\n35. temperature\n36. Thermal Energy\n37. Earthquakes\n38. paleontology\n39. Minerals\n40. Volcanoes\n41. Magnetic Energy\n42. Health\n43. Electrical Energy\n44. Weather\n45. space\n46. Human Body\n47. Fuels and fossils\n48. atmosphere\n49. Ecosystems\n50. Weathering\n51. Changes of State\n52. meteorology\n53. Physical Changes\n54. Position\n55. Motion\n56. Potential Energy\n57. tsunamis\n58. Work\n59. weather\n60. Chemical Changes\n61. Topography\n62. air and water resources\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# Generate Questions\nQuestion Generation: When generating a question, it:\n\nSelects a topic (randomly or specified)\nRetrieves relevant context from the database\nUses Google Gemini to generate a question based on the context","metadata":{}},{"cell_type":"code","source":"import random\nimport json\n\ndef get_question(topic: Optional[str] = None) -> QuestionData:\n    \"\"\"Get a question based on a specific topic or a random topic\"\"\"\n    try:\n        # Select a topic if none provided\n        if not topic:\n            topic = random.choice(topics)\n        \n        # Query the database for relevant context\n        results = db.similarity_search(f\"Information about {topic}\", k=2)\n        context = \"\\n\".join([doc.page_content for doc in results])\n        \n        # Generate a question using the LLM\n        question_data = question_chain.run(\n            context=context,\n            topic=topic\n        )\n        \n        # Parse the JSON response\n        try:\n            # Extract JSON from the response\n            json_str = question_data[question_data.find('{'):question_data.rfind('}')+1]\n            parsed_data = json.loads(json_str)\n            return QuestionData(\n                question=parsed_data[\"question\"],\n                options=parsed_data[\"options\"],\n                correct_answer=parsed_data[\"correct_answer\"],\n                explanation=parsed_data[\"explanation\"],\n                topic=parsed_data[\"topic\"]\n            )\n        except json.JSONDecodeError:\n            # Fallback if JSON parsing fails\n            print(\"Error parsing question data. Using fallback question.\")\n            return QuestionData(\n                question=f\"What is the main component of {topic}?\",\n                options=[\"Option 1\", \"Option 2\", \"Option 3\", \"Option 4\"],\n                correct_answer=\"Option 1\",\n                explanation=f\"This is a fallback question about {topic}.\",\n                topic=topic\n            )\n    except Exception as e:\n        print(f\"Error generating question: {e}\")\n        # Return a fallback question\n        return QuestionData(\n            question=\"What is the chemical symbol for water?\",\n            options=[\"H2O\", \"CO2\", \"O2\", \"NaCl\"],\n            correct_answer=\"H2O\",\n            explanation=\"H2O is the chemical formula for water, representing two hydrogen atoms and one oxygen atom.\",\n            topic=\"Chemistry\"\n        )\n\n# Generate a sample question\nsample_question = get_question()\n\n# Display the question\nprint(f\"\\nSample Question - Topic: {sample_question['topic']}\")\nprint(f\"Question: {sample_question['question']}\")\nfor i, option in enumerate(sample_question['options'], 1):\n    print(f\"{i}. {option}\")\n\n# Display the correct answer and explanation\nprint(f\"\\nCorrect answer: {sample_question['correct_answer']}\")\nprint(f\"Explanation: {sample_question['explanation']}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T16:50:15.956618Z","iopub.execute_input":"2025-04-20T16:50:15.956982Z","iopub.status.idle":"2025-04-20T16:50:17.185806Z","shell.execute_reply.started":"2025-04-20T16:50:15.956953Z","shell.execute_reply":"2025-04-20T16:50:17.184993Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/131951156.py:16: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n  question_data = question_chain.run(\n","output_type":"stream"},{"name":"stdout","text":"\nSample Question - Topic: Magnetic Energy\nQuestion: Which of these uses magnetic energy to work?\n1. A light bulb turning on\n2. A swing moving back and forth\n3. A magnet holding pictures on a fridge\n4. A bicycle moving\n\nCorrect answer: A magnet holding pictures on a fridge\nExplanation: Magnets use magnetic energy to attract and hold things. The magnet on the fridge uses this energy to stick.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"# Run a Quiz session\n\nInteractive Quiz: The user answers questions and receives immediate feedback.\n\nScore Tracking: The application keeps track of correct and incorrect answers.\n\nReview System: At the end, it shows missed questions with explanations.","metadata":{}},{"cell_type":"code","source":"def start_quiz(num_questions: int = 5) -> None:\n    \"\"\"Start a quiz session\"\"\"\n    # Initialize quiz state\n    state = QuizState(\n        score=0,\n        total_questions=num_questions,\n        current_question=None,\n        missed_questions=[],\n        status=\"PLAYING\"\n    )\n    \n    print(f\"\\nWelcome to Science Trivia!\")\n    print(f\"You'll be asked {num_questions} questions about various science topics.\")\n    print(\"Type 'hint' to see the explanation for the current question.\")\n    print(\"Press Enter after typing your answer.\\n\")\n\n    # Ask questions\n    for i in range(num_questions):\n        # Get a random question\n        question = get_question()\n        state[\"current_question\"] = question\n        \n        # Display the question\n        print(f\"\\nQuestion {i+1}/{num_questions} - Topic: {question['topic']}\")\n        print(f\"Question: {question['question']}\")\n        for j, option in enumerate(question[\"options\"], 1):\n            print(f\"{j}. {option}\")\n        \n        # Get user input\n        user_input = input(\"\\nEnter your answer (1-4) or 'hint' for explanation: \").strip().lower()\n        \n        if user_input == 'hint':\n            print(f\"Explanation: {question['explanation']}\")\n            continue\n        \n        try:\n            answer_index = int(user_input) - 1\n            if 0 <= answer_index < len(question[\"options\"]):\n                selected_answer = question[\"options\"][answer_index]\n                \n                if selected_answer == question[\"correct_answer\"]:\n                    print(\"Correct! ✓\")\n                    print(f\"Explanation: {question['explanation']}\")\n                    state[\"score\"] += 1\n                else:\n                    print(f\"Incorrect. The correct answer is: {question['correct_answer']}\")\n                    print(f\"Explanation: {question['explanation']}\")\n                    state[\"missed_questions\"].append(question)\n            else:\n                print(\"Invalid choice. Please enter a number between 1 and 4.\")\n        except ValueError:\n            print(\"Please enter a valid number or 'hint'.\")\n    \n    # Show final score\n    print(f\"\\nQuiz complete! Your score: {state['score']}/{state['total_questions']}\")\n    \n    # Review missed questions\n    if state[\"missed_questions\"]:\n        print(\"\\nQuestions to review:\")\n        for question in state[\"missed_questions\"]:\n            print(f\"\\nTopic: {question['topic']}\")\n            print(f\"Question: {question['question']}\")\n            print(f\"Correct answer: {question['correct_answer']}\")\n            print(f\"Explanation: {question['explanation']}\")\n            input(\"Press Enter to continue...\")\n\n# Run a quiz with 5 questions\nstart_quiz(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T16:52:52.216475Z","iopub.execute_input":"2025-04-20T16:52:52.216779Z","iopub.status.idle":"2025-04-20T16:54:15.651651Z","shell.execute_reply.started":"2025-04-20T16:52:52.216756Z","shell.execute_reply":"2025-04-20T16:54:15.650682Z"}},"outputs":[{"name":"stdout","text":"\nWelcome to Science Trivia!\nYou'll be asked 5 questions about various science topics.\nType 'hint' to see the explanation for the current question.\nPress Enter after typing your answer.\n\n\nQuestion 1/5 - Topic: Force\nQuestion: Which of these is an example of a force making something move?\n1. A book sitting on a table.\n2. A ball rolling down a hill.\n3. A lightbulb glowing.\n4. Ice melting in the sun.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nEnter your answer (1-4) or 'hint' for explanation:  2\n"},{"name":"stdout","text":"Correct! ✓\nExplanation: A force, like gravity, is causing the ball to move down the hill. The book is not moving, the lightbulb is producing light, and the ice is changing state due to heat, not a direct force causing motion.\n\nQuestion 2/5 - Topic: Animal Adaptations\nQuestion: A cactus lives in the desert where it doesn't rain very often. Which adaptation helps the cactus survive in this dry environment?\n1. Brightly colored flowers to attract insects.\n2. Sharp thorns to protect it from animals eating it.\n3. A long, deep root system to absorb water from the ground.\n4. Large, wide leaves to catch as much sunlight as possible.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nEnter your answer (1-4) or 'hint' for explanation:  3\n"},{"name":"stdout","text":"Correct! ✓\nExplanation: A cactus needs to find water in a dry place. A long, deep root system helps it reach water far underground. The other options are not the primary ways a cactus adapts to a desert environment.\n\nQuestion 3/5 - Topic: Magnetic Energy\nQuestion: Which of these uses magnetic energy to work?\n1. A light bulb turning on\n2. A swing moving back and forth\n3. A refrigerator magnet sticking to the fridge\n4. A bicycle rolling down a hill\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nEnter your answer (1-4) or 'hint' for explanation:  3\n"},{"name":"stdout","text":"Correct! ✓\nExplanation: Refrigerator magnets use magnetic energy to stick to metal surfaces like a fridge. The other options use different types of energy like electrical (light bulb), kinetic (swing and bicycle).\n\nQuestion 4/5 - Topic: Rocks\nQuestion: Imagine you find a rock with lots of different pebbles and sand grains stuck together. What type of rock is it most likely to be?\n1. Metamorphic\n2. Igneous\n3. Sedimentary\n4. A mineral\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nEnter your answer (1-4) or 'hint' for explanation:  3\n"},{"name":"stdout","text":"Correct! ✓\nExplanation: Sedimentary rocks are formed from small pieces of other rocks and materials that get pressed and cemented together over time. The pebbles and sand grains are clues that it's sedimentary.\n\nQuestion 5/5 - Topic: Climate\nQuestion: Imagine you live in a place that is hot and sunny almost every day of the year. What is this an example of?\n1. Weather changing quickly\n2. Climate being consistent\n3. A storm happening\n4. The water cycle starting\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nEnter your answer (1-4) or 'hint' for explanation:  2\n"},{"name":"stdout","text":"Correct! ✓\nExplanation: Climate describes the usual weather pattern of a place over a long time. If a place is hot and sunny almost every day, that's its climate.\n\nQuiz complete! Your score: 5/5\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"## Generate a Question for a Specific Topic\n\nLearn by selecting specific topic","metadata":{}},{"cell_type":"code","source":"def generate_topic_question(topic_name: str) -> None:\n    \"\"\"Generate and display a question for a specific topic\"\"\"\n    question = get_question(topic_name)\n    \n    print(f\"Question - Topic: {question['topic']}\")\n    print(f\"Question: {question['question']}\")\n    for i, option in enumerate(question['options'], 1):\n        print(f\"{i}. {option}\")\n    \n    print(f\"\\nCorrect answer: {question['correct_answer']}\")\n    print(f\"Explanation: {question['explanation']}\")\n    \n    return question\n\n# Example: Generate a question for a specific topic\nprint(\"Available topics:\")\nfor i, topic in enumerate(topics, 1):\n    print(f\"{i}. {topic}\")\n\ntopic_index = int(input(\"\\nEnter the number of the topic (1-{}): \".format(len(topics)))) - 1\nif 0 <= topic_index < len(topics):\n    generate_topic_question(topics[topic_index])\nelse:\n    print(\"Invalid topic number.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T16:54:37.812747Z","iopub.execute_input":"2025-04-20T16:54:37.813082Z","iopub.status.idle":"2025-04-20T16:54:45.989185Z","shell.execute_reply.started":"2025-04-20T16:54:37.813057Z","shell.execute_reply":"2025-04-20T16:54:45.988251Z"}},"outputs":[{"name":"stdout","text":"Available topics:\n1. Rocks\n2. wind\n3. Speed\n4. Kinetic Energy\n5. precipitation\n6. water vapor\n7. Force\n8. Physical Sciences\n9. Landforms\n10. Seasons\n11. Gravity\n12. water cycle\n13. condensation\n14. soil\n15. Climate\n16. weather instruments\n17. clouds\n18. evaporation\n19. storms\n20. Simple Machines\n21. Plant Adaptations\n22. Animal Adaptations\n23. Habitats\n24. Light Energy\n25. drought\n26. Life Sciences\n27. Food Webs\n28. Earth Sciences\n29. Human Adaptations\n30. Food Chains\n31. Scientific Inquiry\n32. Sound Energy\n33. Soil types\n34. Erosion\n35. temperature\n36. Thermal Energy\n37. Earthquakes\n38. paleontology\n39. Minerals\n40. Volcanoes\n41. Magnetic Energy\n42. Health\n43. Electrical Energy\n44. Weather\n45. space\n46. Human Body\n47. Fuels and fossils\n48. atmosphere\n49. Ecosystems\n50. Weathering\n51. Changes of State\n52. meteorology\n53. Physical Changes\n54. Position\n55. Motion\n56. Potential Energy\n57. tsunamis\n58. Work\n59. weather\n60. Chemical Changes\n61. Topography\n62. air and water resources\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nEnter the number of the topic (1-62):  59\n"},{"name":"stdout","text":"Question - Topic: weather\nQuestion: Imagine you see puffy, white clouds that look like cotton balls in the sky. What kind of weather might you expect?\n1. A big thunderstorm with lots of rain\n2. A sunny day with fair weather\n3. A long period of very dry weather\n4. A snowstorm with strong winds\n\nCorrect answer: A sunny day with fair weather\nExplanation: Puffy, white clouds called cumulus clouds often mean good weather. They form when warm air rises, but they usually don't bring rain unless they get very big.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"# The Future is Bright (and Full of Science!):\n\nLooking ahead, I'm excited to evolve this project further. My future plans include leveraging agentic AI. Imagine converting the current RAG-based notebook into a more sophisticated agentic AI application. This would allow for more dynamic interactions, where the AI could understand the child's learning progress, proactively suggest relevant topics, and even guide them through mini-science explorations.\n\nFurthermore, the goal is to develop a user-friendly UI interaction specifically designed for kids. This intuitive interface would make it easy for my 8-year-old (and others!) to select topics, engage with the quizzes, and learn in a fun and accessible way. By combining the power of RAG with the proactive capabilities of agentic AI and a child-friendly interface, we can create an even more personalized and engaging science learning journey.\n\nThis project is more than just a quiz generator; it's a step towards creating a personalized and engaging science learning environment for my child. By harnessing the power of AI, we can transform static information into a dynamic tool that fuels their curiosity and empowers them to explore the wonders of science at their own pace. And who knows, maybe it will inspire other busy parents to do the same!","metadata":{}}]}